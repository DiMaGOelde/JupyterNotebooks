{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter-Notebook für ein eigenes KNN\n",
    "\n",
    "Hier wird ein KNN trainiert und getestet zum Erkennen von Ziffern.\n",
    "\n",
    "Die Ziffern (0, 1, ..., 9) liegen als Graustufenbilder in der Auflösung 28x28 vor, sind als CSV-Datei verfügbar als sog. MNIST-Datensatz.\n",
    "\n",
    "- **Code für ein 3-schichtiges KNN (Input - Hidden - Output)**\n",
    "- **Code zum Trainieren des Netzes für die MNIST-Daten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der notwendigen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio.v2 as imageio\n",
    "import glob\n",
    "\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Klasse für ein neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-schichtiges Neuronales Netz**\n",
    "\n",
    "Parameter:\n",
    "- Anzahl Neuronen des Input Layer\n",
    "- Anzahl Neuronen des Hidden Layer\n",
    "- Anzahl Neuronen des Output-Layer\n",
    "- Lernrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setzen und KNN aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "knn = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten (ggf. entpacken und) laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falls die CSV-Datei nur gezipped vorliegt:\n",
    "- führen Sie die folgende Zelle aus, und dann nicht(!) die übernächste\n",
    "\n",
    "ansonsten\n",
    "- führen Sie nur die übernächste Zelle aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zippen\n",
    "\n",
    "training_data_list = zippen.zip_entpacken (\"mnist_train\", \"mnist_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der Trainingsdatensatz ist zeilenweise aufgebaut. \n",
    "- Jede Zeile ist jetzt als String in einer Liste vorhanden.\n",
    "- Dieser String enthält 785 Integerwerte, jeweils durch ein Komma getrennt.\n",
    "  - Der erste Eintrag ist die dargestellt Ziffer\n",
    "  - die folgenden 784 Einträge sind die 28x28 Pixelwerte, also Werte aus [0, 255]\n",
    "  \n",
    "Beispielsweise hier der 0-te Datensatz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "print (\"Bitte warten!\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(e+1, \"von\", epochs, \"Epochen gestartet.... \", end = \"\")\n",
    "    # Alle Einträge in den Trainingsdaten werden durchgegangen\n",
    "    for record in training_data_list:\n",
    "        # Aufspalten der Dateneinträge (Komma-separiert)\n",
    "        all_values = record.split(',')\n",
    "        # Skalieren der Werte in den Bereich zwischen 0 und 1\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        knn.train(inputs, targets)\n",
    "        pass\n",
    "    print (\"done\")\n",
    "    pass\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alle Trainingsdaten testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Zur Kontrolle werden alle Trainingsdaten getestet, da (natürlich) ein KNN in der Regel nicht notwendigerweise alle Trainingsdaten korrekt klassifiziert.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_data(data_list):\n",
    "    korrekte = 0\n",
    "    anzahl = len(data_list)\n",
    "    wrongIndizes = []\n",
    "    \n",
    "    for index in range (anzahl):\n",
    "        \n",
    "        img_array = np.asfarray(data_list[index].split(\",\"))[1:].astype(int)\n",
    "        img_data  = img_array\n",
    "        img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # data is remaining values\n",
    "        inputs = img_data\n",
    "\n",
    "        # query the network\n",
    "        outputs = knn.query(inputs)\n",
    "        \n",
    "        # the index of the highest value corresponds to the label\n",
    "        label = np.argmax(outputs)\n",
    "        correct_label = int(data_list[index][0])\n",
    " \n",
    "        if (label == correct_label):\n",
    "            korrekte += 1\n",
    "        else:\n",
    "            wrongIndizes.append(index)\n",
    "    print (\"Von den\", anzahl, \"Daten sind\", korrekte, \"korrekt,\", anzahl - korrekte, \"falsch zugeordnet\")\n",
    "    # print(wrongIndizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_data(training_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie gut wurden die Trainingsdaten klassifiziert?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst eine Hilfsfunktion:\n",
    "- `data_list` enthält wahlweise die Trainings- oder die Testdaten\n",
    "- `index` ist der Index des untersuchten Eintrags in der Liste\n",
    "\n",
    "Die Funktion liefert ein Tupel von Labeln:\n",
    "- Dasjenige Label, das der Eintrag laut Liste haben soll\n",
    "- Das Label das das KNN liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soll_ist (index, data_list):\n",
    "    img_array = np.asfarray(data_list[index].split(\",\"))[1:].astype(int)\n",
    "    img_data  = img_array\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    inputs = img_data\n",
    "\n",
    "    # query the network\n",
    "    outputs = knn.query(inputs)\n",
    "    label = np.argmax(outputs)\n",
    "    correct_label = int(data_list[index][0])\n",
    "    return (correct_label, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funtion kann man alle Daten testen. Es wird eine Numpy-Matrix erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soll_ist_all(data_list):\n",
    "    m = np.zeros((10, 10), dtype = int)\n",
    "    anzahl = len(data_list)\n",
    "    for index in range (anzahl):\n",
    "        s, i = soll_ist (index, data_list)\n",
    "        m [s][i] += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Tabelle sind die Fehler aufgelistet.\n",
    "\n",
    "- Steht z.B. in der 3-ten Zeile der Wert 17 in der 4-ten Spalte, wurde 17 mal die Ziffer `3` fälschlicherweise als Ziffer `4` erkannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_train = soll_ist_all(training_data_list)\n",
    "df = pd.DataFrame(data=sia_train)\n",
    "df[\"Fehler\"] = \"\"\n",
    "\n",
    "for i in range (10):\n",
    "    f = 0;\n",
    "    for j in range (10):\n",
    "        if i != j:\n",
    "            inhalt = int (df[j][i])\n",
    "            f += int (inhalt)\n",
    "    df[\"Fehler\"][i] = f\n",
    "\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie gut werden mit diesem KNN die Testdaten klassifiziert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sieht man den 0-ten Datensatz der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_test = soll_ist_all(test_data_list)\n",
    "\n",
    "df = pd.DataFrame(data=sia_test)\n",
    "df[\"Fehler\"] = \"\"\n",
    "\n",
    "for i in range (10):\n",
    "    f = 0;\n",
    "    for j in range (10):\n",
    "        if i != j:\n",
    "            inhalt = int (df[j][i])\n",
    "            f += int (inhalt)\n",
    "    df[\"Fehler\"][i] = f\n",
    "\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigene Bilder laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitte die geünschten Testdaten angeben!**\n",
    "\n",
    "- Man kann mehrere Bilder testen. Alle Bilder liegen in einem Unterverzeichnis.\n",
    "- Der Name jeder Bild-Datei in diesem Unterverzeichnis hat die Form \"xxx_n.png\", wobei \"xxx\" ein beliebiger Text ist und \"n\" das Label (also die in dem Bild dargestellt Ziffer) ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images/2828_my_own_?.png'):\n",
    "#for image_file_name in glob.glob('Meine_Fotos/2828_bov_?.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = np.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eine eigenes Bild aus dieser Bildersammlung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nummer des Testbildes:\n",
    "# record to test\n",
    "item = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# plot image\n",
    "plt.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = knn.query(inputs)\n",
    "for i in range (output_nodes):\n",
    "    print (f'Güte der Erkennung = {outputs[i][0]:1.5f} für die Ziffer {i}')\n",
    "        \n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = np.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!, should be\", int(correct_label))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alle eigenen Bilder testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range (len(our_own_dataset)):\n",
    "    \n",
    "    # correct answer is first value\n",
    "    correct_label = our_own_dataset[item][0]\n",
    "    # data is remaining values\n",
    "    inputs = our_own_dataset[item][1:]\n",
    "\n",
    "    # query the network\n",
    "    outputs = knn.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    print(\"Bildnummer\", item, \": network says:\", label, \"; shoud be:\", int(correct_label))\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        print (\"match!\")\n",
    "    else:\n",
    "        print (\"no match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein eigenes Bild testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testen (image_file_name, correct_label):\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    #print(numpy.min(img_data))\n",
    "    #print(numpy.max(img_data))\n",
    "        \n",
    "    # plot image\n",
    "    plt.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "    # data is remaining values\n",
    "    inputs = img_data\n",
    "\n",
    "    # query the network\n",
    "    outputs = knn.query(inputs)\n",
    "    for i in range (output_nodes):\n",
    "        print (f'Güte der Erkennung {outputs[i][0]:1.5f} für die Ziffer {i}')\n",
    "        \n",
    "    \n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    print(\"network says \", label)\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        print (\"match!\")\n",
    "    else:\n",
    "        print (\"no match!, should be\", int(correct_label))\n",
    "\n",
    "    \n",
    "testen ('Meine_Fotos/2828_bov_4.png', 5)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Inhalt",
   "title_sidebar": "Inhalt",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
